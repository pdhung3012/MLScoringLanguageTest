Result for GaussianNB(priors=None, var_smoothing=1e-09)
0.6931818243510471
[[1990  488    3   64]
 [ 326  641    9  309]
 [   3    1  315   17]
 [  59  171   52  451]]
              precision    recall  f1-score   support

        I-MF       0.84      0.78      0.81      2545
        I-MM       0.49      0.50      0.50      1285
        I-NE       0.83      0.94      0.88       336
        I-SE       0.54      0.62      0.57       733

   micro avg       0.69      0.69      0.69      4899
   macro avg       0.67      0.71      0.69      4899
weighted avg       0.70      0.69      0.70      4899

Result for LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='warn',
          n_jobs=None, penalty='l2', random_state=1234, solver='warn',
          tol=0.0001, verbose=0, warm_start=False)
0.7570776879607134
[[2414  130    1    0]
 [ 586  689    0   10]
 [  24   34  219   59]
 [ 163  179    3  388]]
              precision    recall  f1-score   support

        I-MF       0.76      0.95      0.84      2545
        I-MM       0.67      0.54      0.59      1285
        I-NE       0.98      0.65      0.78       336
        I-SE       0.85      0.53      0.65       733

   micro avg       0.76      0.76      0.76      4899
   macro avg       0.81      0.67      0.72      4899
weighted avg       0.76      0.76      0.74      4899

Result for DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,
            max_features=None, max_leaf_nodes=None,
            min_impurity_decrease=0.0, min_impurity_split=None,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, presort=False, random_state=None,
            splitter='best')
0.874442373975653
[[2344  173    5   23]
 [ 189 1028    4   64]
 [  14    4  301   17]
 [  35   59   19  620]]
              precision    recall  f1-score   support

        I-MF       0.91      0.92      0.91      2545
        I-MM       0.81      0.80      0.81      1285
        I-NE       0.91      0.90      0.91       336
        I-SE       0.86      0.85      0.85       733

   micro avg       0.88      0.88      0.88      4899
   macro avg       0.87      0.87      0.87      4899
weighted avg       0.88      0.88      0.88      4899

Result for RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',
            max_depth=None, max_features='auto', max_leaf_nodes=None,
            min_impurity_decrease=0.0, min_impurity_split=None,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=None,
            oob_score=False, random_state=1234, verbose=0,
            warm_start=False)
0.9004068658751768
[[2387  149    3    6]
 [ 181 1067    1   36]
 [   8    5  317    6]
 [  21   56   10  646]]
              precision    recall  f1-score   support

        I-MF       0.92      0.94      0.93      2545
        I-MM       0.84      0.83      0.83      1285
        I-NE       0.96      0.94      0.95       336
        I-SE       0.93      0.88      0.91       733

   micro avg       0.90      0.90      0.90      4899
   macro avg       0.91      0.90      0.90      4899
weighted avg       0.90      0.90      0.90      4899

Result for AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,
          learning_rate=1.0, n_estimators=50, random_state=None)
0.7673367800473094
[[2166  372    1    6]
 [ 393  831    0   61]
 [   6    5  302   23]
 [  53  216   10  454]]
              precision    recall  f1-score   support

        I-MF       0.83      0.85      0.84      2545
        I-MM       0.58      0.65      0.61      1285
        I-NE       0.96      0.90      0.93       336
        I-SE       0.83      0.62      0.71       733

   micro avg       0.77      0.77      0.77      4899
   macro avg       0.80      0.75      0.77      4899
weighted avg       0.77      0.77      0.77      4899

Result for LinearDiscriminantAnalysis(n_components=None, priors=None, shrinkage=None,
              solver='svd', store_covariance=False, tol=0.0001)
0.9140513979831579
[[2381  126    2   36]
 [  63 1186    0   36]
 [   8   66  216   46]
 [   9   33    1  690]]
              precision    recall  f1-score   support

        I-MF       0.97      0.94      0.95      2545
        I-MM       0.84      0.92      0.88      1285
        I-NE       0.99      0.64      0.78       336
        I-SE       0.85      0.94      0.90       733

   micro avg       0.91      0.91      0.91      4899
   macro avg       0.91      0.86      0.88      4899
weighted avg       0.92      0.91      0.91      4899

Result for QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
               store_covariance=False, store_covariances=None, tol=0.0001)
0.926117783095967
[[2399  126    5   15]
 [  91 1172    2   20]
 [   5   13  298   20]
 [  13   40    7  673]]
              precision    recall  f1-score   support

        I-MF       0.96      0.94      0.95      2545
        I-MM       0.87      0.91      0.89      1285
        I-NE       0.96      0.89      0.92       336
        I-SE       0.92      0.92      0.92       733

   micro avg       0.93      0.93      0.93      4899
   macro avg       0.93      0.91      0.92      4899
weighted avg       0.93      0.93      0.93      4899

Result for LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,
     intercept_scaling=1, loss='squared_hinge', max_iter=1000,
     multi_class='ovr', penalty='l2', random_state=1234, tol=0.0001,
     verbose=0)
0.8979412060264712
[[2446   80    2   17]
 [ 245 1022    0   18]
 [  14   19  282   21]
 [  35   42    4  652]]
              precision    recall  f1-score   support

        I-MF       0.89      0.96      0.93      2545
        I-MM       0.88      0.80      0.83      1285
        I-NE       0.98      0.84      0.90       336
        I-SE       0.92      0.89      0.90       733

   micro avg       0.90      0.90      0.90      4899
   macro avg       0.92      0.87      0.89      4899
weighted avg       0.90      0.90      0.90      4899

Result for MLPClassifier(activation='relu', alpha=1, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(100,), learning_rate='constant',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,
       random_state=None, shuffle=True, solver='adam', tol=0.0001,
       validation_fraction=0.1, verbose=False, warm_start=False)
0.677320729919853
[[2340  199    1    5]
 [ 611  598    0   76]
 [  11   41  143  141]
 [ 126  387   15  205]]
              precision    recall  f1-score   support

        I-MF       0.76      0.92      0.83      2545
        I-MM       0.49      0.47      0.48      1285
        I-NE       0.90      0.43      0.58       336
        I-SE       0.48      0.28      0.35       733

   micro avg       0.67      0.67      0.67      4899
   macro avg       0.66      0.52      0.56      4899
weighted avg       0.66      0.67      0.65      4899

Result for GradientBoostingClassifier(criterion='friedman_mse', init=None,
              learning_rate=0.1, loss='deviance', max_depth=5,
              max_features=None, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=1, min_samples_split=2,
              min_weight_fraction_leaf=0.0, n_estimators=100,
              n_iter_no_change=None, presort='auto', random_state=1234,
              subsample=1.0, tol=0.0001, validation_fraction=0.1,
              verbose=0, warm_start=False)
0.9267145843881115
[[2422  109    2   12]
 [ 111 1152    2   20]
 [   3    7  320    6]
 [  25   39    8  661]]
              precision    recall  f1-score   support

        I-MF       0.95      0.95      0.95      2545
        I-MM       0.88      0.90      0.89      1285
        I-NE       0.96      0.95      0.96       336
        I-SE       0.95      0.90      0.92       733

   micro avg       0.93      0.93      0.93      4899
   macro avg       0.93      0.93      0.93      4899
weighted avg       0.93      0.93      0.93      4899

