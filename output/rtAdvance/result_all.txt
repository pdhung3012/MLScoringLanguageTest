Result for GaussianNB(priors=None, var_smoothing=1e-09)
0.7470914079145787
[[1039  107]
 [ 622 1103]]
              precision    recall  f1-score   support

        MMMF       0.63      0.91      0.74      1146
        NESE       0.91      0.64      0.75      1725

   micro avg       0.75      0.75      0.75      2871
   macro avg       0.77      0.77      0.75      2871
weighted avg       0.80      0.75      0.75      2871

Result for LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='warn',
          n_jobs=None, penalty='l2', random_state=1234, solver='warn',
          tol=0.0001, verbose=0, warm_start=False)
0.82411272670419
[[ 897  249]
 [ 258 1467]]
              precision    recall  f1-score   support

        MMMF       0.78      0.78      0.78      1146
        NESE       0.85      0.85      0.85      1725

   micro avg       0.82      0.82      0.82      2871
   macro avg       0.82      0.82      0.82      2871
weighted avg       0.82      0.82      0.82      2871

Result for DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,
            max_features=None, max_leaf_nodes=None,
            min_impurity_decrease=0.0, min_impurity_split=None,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, presort=False, random_state=None,
            splitter='best')
0.9369646951964026
[[1059   87]
 [  80 1645]]
              precision    recall  f1-score   support

        MMMF       0.93      0.92      0.93      1146
        NESE       0.95      0.95      0.95      1725

   micro avg       0.94      0.94      0.94      2871
   macro avg       0.94      0.94      0.94      2871
weighted avg       0.94      0.94      0.94      2871

Result for RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',
            max_depth=None, max_features='auto', max_leaf_nodes=None,
            min_impurity_decrease=0.0, min_impurity_split=None,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=None,
            oob_score=False, random_state=1234, verbose=0,
            warm_start=False)
0.9467208773611213
[[1068   78]
 [  71 1654]]
              precision    recall  f1-score   support

        MMMF       0.94      0.93      0.93      1146
        NESE       0.95      0.96      0.96      1725

   micro avg       0.95      0.95      0.95      2871
   macro avg       0.95      0.95      0.95      2871
weighted avg       0.95      0.95      0.95      2871

Result for AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,
          learning_rate=1.0, n_estimators=50, random_state=None)
0.9348425033638449
[[1039  107]
 [  90 1635]]
              precision    recall  f1-score   support

        MMMF       0.92      0.91      0.91      1146
        NESE       0.94      0.95      0.94      1725

   micro avg       0.93      0.93      0.93      2871
   macro avg       0.93      0.93      0.93      2871
weighted avg       0.93      0.93      0.93      2871

Result for LinearDiscriminantAnalysis(n_components=None, priors=None, shrinkage=None,
              solver='svd', store_covariance=False, tol=0.0001)
0.9662296291107266
[[1072   74]
 [  23 1702]]
              precision    recall  f1-score   support

        MMMF       0.98      0.94      0.96      1146
        NESE       0.96      0.99      0.97      1725

   micro avg       0.97      0.97      0.97      2871
   macro avg       0.97      0.96      0.96      2871
weighted avg       0.97      0.97      0.97      2871

Result for QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
               store_covariance=False, store_covariances=None, tol=0.0001)
0.978757548345963
[[1118   28]
 [  32 1693]]
              precision    recall  f1-score   support

        MMMF       0.97      0.98      0.97      1146
        NESE       0.98      0.98      0.98      1725

   micro avg       0.98      0.98      0.98      2871
   macro avg       0.98      0.98      0.98      2871
weighted avg       0.98      0.98      0.98      2871

Result for LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,
     intercept_scaling=1, loss='squared_hinge', max_iter=1000,
     multi_class='ovr', penalty='l2', random_state=1234, tol=0.0001,
     verbose=0)
0.9233744829019219
[[1012  134]
 [  88 1637]]
              precision    recall  f1-score   support

        MMMF       0.92      0.88      0.90      1146
        NESE       0.92      0.95      0.94      1725

   micro avg       0.92      0.92      0.92      2871
   macro avg       0.92      0.92      0.92      2871
weighted avg       0.92      0.92      0.92      2871

Result for MLPClassifier(activation='relu', alpha=1, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(100,), learning_rate='constant',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,
       random_state=None, shuffle=True, solver='adam', tol=0.0001,
       validation_fraction=0.1, verbose=False, warm_start=False)
0.8140141193494852
[[ 879  267]
 [ 279 1446]]
              precision    recall  f1-score   support

        MMMF       0.76      0.77      0.76      1146
        NESE       0.84      0.84      0.84      1725

   micro avg       0.81      0.81      0.81      2871
   macro avg       0.80      0.80      0.80      2871
weighted avg       0.81      0.81      0.81      2871

Result for GradientBoostingClassifier(criterion='friedman_mse', init=None,
              learning_rate=0.1, loss='deviance', max_depth=5,
              max_features=None, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=1, min_samples_split=2,
              min_weight_fraction_leaf=0.0, n_estimators=100,
              n_iter_no_change=None, presort='auto', random_state=1234,
              subsample=1.0, tol=0.0001, validation_fraction=0.1,
              verbose=0, warm_start=False)
0.9648201307500088
[[1094   52]
 [  40 1685]]
              precision    recall  f1-score   support

        MMMF       0.96      0.95      0.96      1146
        NESE       0.97      0.98      0.97      1725

   micro avg       0.97      0.97      0.97      2871
   macro avg       0.97      0.97      0.97      2871
weighted avg       0.97      0.97      0.97      2871

