Result for GaussianNB(priors=None, var_smoothing=1e-09)
0.6363497946065036
[[167   1   2  75  45  17   5  20  33]
 [  2 116   0  11   6  13   1   2   8]
 [  1   1 231  48   7   3   3  11   4]
 [  5   2   4 345   8 104   3  92  26]
 [ 33   0   9  39 181   9   0   4   5]
 [  1   0   0   7   0 187   0   0   9]
 [  3   1   1  15   0  10  66  29  37]
 [  6   1  19 153   3  24   5 364  14]
 [  6   0   0   0   0  29   1   2 165]]
                 precision    recall  f1-score   support

       About Me       0.75      0.46      0.57       365
    Best Friend       0.95      0.73      0.83       159
   CELEBRATIONS       0.87      0.75      0.80       309
      CITY_TOWN       0.50      0.59      0.54       589
         FAMILY       0.72      0.65      0.68       280
School Supplies       0.47      0.92      0.62       204
   Things To Do       0.79      0.41      0.54       162
        WEATHER       0.69      0.62      0.65       589
       Wishlist       0.55      0.81      0.65       203

      micro avg       0.64      0.64      0.64      2860
      macro avg       0.70      0.66      0.65      2860
   weighted avg       0.68      0.64      0.64      2860

Result for LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='warn',
          n_jobs=None, penalty='l2', random_state=1234, solver='warn',
          tol=0.0001, verbose=0, warm_start=False)
0.632323447347497
[[173   0   0 117  15   0   0  60   0]
 [  6  14   0 108   0   0   0  31   0]
 [  0   0 207  49   0   0   0  53   0]
 [  0   0   1 550   2   0   0  36   0]
 [  4   0   1  64 196   0   0  15   0]
 [  1   0   0  96   0 105   0   2   0]
 [  2   0   0  88   0   0   0  72   0]
 [  1   0   1  87   0   0   0 500   0]
 [  5   0   0 122   0   0   0  12  64]]
                 precision    recall  f1-score   support

       About Me       0.90      0.47      0.62       365
    Best Friend       1.00      0.09      0.16       159
   CELEBRATIONS       0.99      0.67      0.80       309
      CITY_TOWN       0.43      0.93      0.59       589
         FAMILY       0.92      0.70      0.80       280
School Supplies       1.00      0.51      0.68       204
   Things To Do       0.00      0.00      0.00       162
        WEATHER       0.64      0.85      0.73       589
       Wishlist       1.00      0.32      0.48       203

      micro avg       0.63      0.63      0.63      2860
      macro avg       0.76      0.50      0.54      2860
   weighted avg       0.73      0.63      0.61      2860

Result for DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,
            max_features=None, max_leaf_nodes=None,
            min_impurity_decrease=0.0, min_impurity_split=None,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, presort=False, random_state=None,
            splitter='best')
0.8173606787275347
[[272   2   2  41  18   4   8  13   5]
 [  2 128   3  16   3   1   3   2   1]
 [  5   2 268   7   5   0   4  17   1]
 [ 20   4  12 482  19   5  13  26   8]
 [ 15   2   4  16 227   1   1  10   4]
 [  5   3   0  13   1 178   0   3   1]
 [ 11  10   1  25   1   1 100  10   3]
 [ 18   4  21  26   6   4   4 502   4]
 [  5   2   1  12   1   1   5   1 175]]
                 precision    recall  f1-score   support

       About Me       0.77      0.75      0.76       365
    Best Friend       0.82      0.81      0.81       159
   CELEBRATIONS       0.86      0.87      0.86       309
      CITY_TOWN       0.76      0.82      0.79       589
         FAMILY       0.81      0.81      0.81       280
School Supplies       0.91      0.87      0.89       204
   Things To Do       0.72      0.62      0.67       162
        WEATHER       0.86      0.85      0.86       589
       Wishlist       0.87      0.86      0.86       203

      micro avg       0.82      0.82      0.82      2860
      macro avg       0.82      0.81      0.81      2860
   weighted avg       0.82      0.82      0.82      2860

Result for RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',
            max_depth=None, max_features='auto', max_leaf_nodes=None,
            min_impurity_decrease=0.0, min_impurity_split=None,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=None,
            oob_score=False, random_state=1234, verbose=0,
            warm_start=False)
0.8794099138288356
[[317   1   1  27   8   1   2   7   1]
 [  2 138   0  11   1   0   4   3   0]
 [  3   2 280   6   0   0   2  15   1]
 [ 11   1   4 537   8   1   5  19   3]
 [ 11   0   4  18 240   1   0   6   0]
 [  5   1   0  12   0 183   0   3   0]
 [  7   5   2  18   0   0 121   6   3]
 [ 11   3   6  23   1   2   1 539   3]
 [  6   1   1  11   0   1   1   3 179]]
                 precision    recall  f1-score   support

       About Me       0.85      0.87      0.86       365
    Best Friend       0.91      0.87      0.89       159
   CELEBRATIONS       0.94      0.91      0.92       309
      CITY_TOWN       0.81      0.91      0.86       589
         FAMILY       0.93      0.86      0.89       280
School Supplies       0.97      0.90      0.93       204
   Things To Do       0.89      0.75      0.81       162
        WEATHER       0.90      0.92      0.91       589
       Wishlist       0.94      0.88      0.91       203

      micro avg       0.89      0.89      0.89      2860
      macro avg       0.90      0.87      0.89      2860
   weighted avg       0.89      0.89      0.89      2860

Result for AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,
          learning_rate=1.0, n_estimators=50, random_state=None)
0.5461526342880091
[[160   8   6  66  30   6  17  67   5]
 [ 19  87   2  16   3   3   6  19   4]
 [ 36   1 114  33  16   0   6 103   0]
 [ 32   4   9 328  29   4  11 162  10]
 [ 99   3  10  27  99   2   2  38   0]
 [  4   1   0  17   4 160   3   9   6]
 [ 26   2   2  20   5   4  62  39   2]
 [ 51   2  24  81  18   1  18 391   3]
 [  9   3   0  14   0   7   5  11 154]]
                 precision    recall  f1-score   support

       About Me       0.37      0.44      0.40       365
    Best Friend       0.78      0.55      0.64       159
   CELEBRATIONS       0.68      0.37      0.48       309
      CITY_TOWN       0.54      0.56      0.55       589
         FAMILY       0.49      0.35      0.41       280
School Supplies       0.86      0.78      0.82       204
   Things To Do       0.48      0.38      0.42       162
        WEATHER       0.47      0.66      0.55       589
       Wishlist       0.84      0.76      0.80       203

      micro avg       0.54      0.54      0.54      2860
      macro avg       0.61      0.54      0.56      2860
   weighted avg       0.57      0.54      0.54      2860

Result for LinearDiscriminantAnalysis(n_components=None, priors=None, shrinkage=None,
              solver='svd', store_covariance=False, tol=0.0001)
0.8793636228671675
[[324   1   0  15   4   0  18   3   0]
 [  2 129   0  16   1   0   7   4   0]
 [  6   2 275  10   0   0   3  12   1]
 [ 21   1   1 534   2   0  26   4   0]
 [ 10   0   2  22 234   0   5   7   0]
 [  4   0   0  10   0 169   8  13   0]
 [  5   1   0  13   0   0 140   1   2]
 [ 19   1   3  18   0   0  11 534   3]
 [  4   0   0  12   0   0  10   3 174]]
                 precision    recall  f1-score   support

       About Me       0.82      0.89      0.85       365
    Best Friend       0.96      0.81      0.88       159
   CELEBRATIONS       0.98      0.89      0.93       309
      CITY_TOWN       0.82      0.91      0.86       589
         FAMILY       0.97      0.84      0.90       280
School Supplies       1.00      0.83      0.91       204
   Things To Do       0.61      0.86      0.72       162
        WEATHER       0.92      0.91      0.91       589
       Wishlist       0.97      0.86      0.91       203

      micro avg       0.88      0.88      0.88      2860
      macro avg       0.89      0.87      0.87      2860
   weighted avg       0.89      0.88      0.88      2860

Result for QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
               store_covariance=False, store_covariances=None, tol=0.0001)
0.8888945579665879
[[314   1   0  13   7   2  19   6   3]
 [  2 136   0   1   3   4   6   0   7]
 [  2   1 289   6   1   0   0   7   3]
 [ 14   2   4 505   8  12  26   8  10]
 [  6   0   1  10 253   3   3   4   0]
 [  0   0   0   0   0 190   8   1   5]
 [  4   1   1   7   0   2 136   5   6]
 [  9   3   5  10   5   5  11 537   4]
 [  3   1   1   2   0   2   9   1 184]]
                 precision    recall  f1-score   support

       About Me       0.89      0.86      0.87       365
    Best Friend       0.94      0.86      0.89       159
   CELEBRATIONS       0.96      0.94      0.95       309
      CITY_TOWN       0.91      0.86      0.88       589
         FAMILY       0.91      0.90      0.91       280
School Supplies       0.86      0.93      0.90       204
   Things To Do       0.62      0.84      0.72       162
        WEATHER       0.94      0.91      0.93       589
       Wishlist       0.83      0.91      0.87       203

      micro avg       0.89      0.89      0.89      2860
      macro avg       0.87      0.89      0.88      2860
   weighted avg       0.90      0.89      0.89      2860

Result for LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,
     intercept_scaling=1, loss='squared_hinge', max_iter=1000,
     multi_class='ovr', penalty='l2', random_state=1234, tol=0.0001,
     verbose=0)
0.8796449812106829
[[313   0   1  29   9   0   8   4   1]
 [  3 128   0  20   2   0   4   2   0]
 [  5   2 283   6   0   0   1  11   1]
 [ 12   1   2 539   6   1  16  11   1]
 [  9   0   6  18 238   1   3   5   0]
 [  3   0   0  15   0 178   4   4   0]
 [  7   1   0  26   0   0 122   4   2]
 [ 12   1   5  23   0   1   2 542   3]
 [  7   0   0  13   0   0   7   1 175]]
                 precision    recall  f1-score   support

       About Me       0.84      0.86      0.85       365
    Best Friend       0.96      0.81      0.88       159
   CELEBRATIONS       0.95      0.92      0.93       309
      CITY_TOWN       0.78      0.92      0.84       589
         FAMILY       0.93      0.85      0.89       280
School Supplies       0.98      0.87      0.92       204
   Things To Do       0.73      0.75      0.74       162
        WEATHER       0.93      0.92      0.92       589
       Wishlist       0.96      0.86      0.91       203

      micro avg       0.88      0.88      0.88      2860
      macro avg       0.90      0.86      0.88      2860
   weighted avg       0.89      0.88      0.88      2860

Result for MLPClassifier(activation='relu', alpha=1, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(100,), learning_rate='constant',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,
       random_state=None, shuffle=True, solver='adam', tol=0.0001,
       validation_fraction=0.1, verbose=False, warm_start=False)
0.6111498775762746
[[189   0   0  91  33   0   0  52   0]
 [ 34   0   0 103   8   0   0  14   0]
 [  0   0 223  37   0   0   0  49   0]
 [  1   0   2 534   4   0   0  48   0]
 [ 35   0   4  46 189   0   0   6   0]
 [  2   0   0 100   0 102   0   0   0]
 [ 12   0   0  76   0   0   0  73   1]
 [  7   0   2  96   0   0   0 484   0]
 [ 19   0   0  94   0  73   0   5  12]]
                 precision    recall  f1-score   support

       About Me       0.63      0.52      0.57       365
    Best Friend       0.00      0.00      0.00       159
   CELEBRATIONS       0.97      0.72      0.83       309
      CITY_TOWN       0.45      0.91      0.60       589
         FAMILY       0.81      0.68      0.74       280
School Supplies       0.58      0.50      0.54       204
   Things To Do       0.00      0.00      0.00       162
        WEATHER       0.66      0.82      0.73       589
       Wishlist       0.92      0.06      0.11       203

      micro avg       0.61      0.61      0.61      2860
      macro avg       0.56      0.47      0.46      2860
   weighted avg       0.60      0.61      0.56      2860

Result for GradientBoostingClassifier(criterion='friedman_mse', init=None,
              learning_rate=0.1, loss='deviance', max_depth=5,
              max_features=None, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=1, min_samples_split=2,
              min_weight_fraction_leaf=0.0, n_estimators=100,
              n_iter_no_change=None, presort='auto', random_state=1234,
              subsample=1.0, tol=0.0001, validation_fraction=0.1,
              verbose=0, warm_start=False)
0.8913005832903742
[[313   1   0  31   7   1   2  10   0]
 [  1 134   0  14   2   1   2   4   1]
 [  4   0 282   3   2   0   1  17   0]
 [ 12   2   4 538   7   3   6  17   0]
 [  8   0   2  16 244   0   0  10   0]
 [  3   1   0  13   0 183   0   4   0]
 [  7   4   0  23   0   0 120   7   1]
 [ 12   3   4  24   2   2   2 540   0]
 [  3   2   0  12   0   1   1   1 183]]
                 precision    recall  f1-score   support

       About Me       0.86      0.86      0.86       365
    Best Friend       0.91      0.84      0.88       159
   CELEBRATIONS       0.97      0.91      0.94       309
      CITY_TOWN       0.80      0.91      0.85       589
         FAMILY       0.92      0.87      0.90       280
School Supplies       0.96      0.90      0.93       204
   Things To Do       0.90      0.74      0.81       162
        WEATHER       0.89      0.92      0.90       589
       Wishlist       0.99      0.90      0.94       203

      micro avg       0.89      0.89      0.89      2860
      macro avg       0.91      0.87      0.89      2860
   weighted avg       0.89      0.89      0.89      2860

