Result for GaussianNB(priors=None, var_smoothing=1e-09)
0.511571921365592
[[747 293  43  83]
 [278 277  82  69]
 [ 36  29 242  49]
 [241 118  96 177]]
              precision    recall  f1-score   support

        N-MF       0.57      0.64      0.61      1166
        N-MM       0.39      0.39      0.39       706
        N-NE       0.52      0.68      0.59       356
        N-SE       0.47      0.28      0.35       632

   micro avg       0.50      0.50      0.50      2860
   macro avg       0.49      0.50      0.48      2860
weighted avg       0.50      0.50      0.49      2860

Result for LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='warn',
          n_jobs=None, penalty='l2', random_state=1234, solver='warn',
          tol=0.0001, verbose=0, warm_start=False)
0.5269289006396101
[[1108   56    2    0]
 [ 571  132    3    0]
 [ 112   75  163    6]
 [ 495   21    6  110]]
              precision    recall  f1-score   support

        N-MF       0.48      0.95      0.64      1166
        N-MM       0.46      0.19      0.27       706
        N-NE       0.94      0.46      0.62       356
        N-SE       0.95      0.17      0.29       632

   micro avg       0.53      0.53      0.53      2860
   macro avg       0.71      0.44      0.45      2860
weighted avg       0.64      0.53      0.47      2860

Result for DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,
            max_features=None, max_leaf_nodes=None,
            min_impurity_decrease=0.0, min_impurity_split=None,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, presort=False, random_state=None,
            splitter='best')
0.8430445477744515
[[1021   55   33   57]
 [  75  593   21   17]
 [  47   21  264   24]
 [  65   22   21  524]]
              precision    recall  f1-score   support

        N-MF       0.85      0.88      0.86      1166
        N-MM       0.86      0.84      0.85       706
        N-NE       0.78      0.74      0.76       356
        N-SE       0.84      0.83      0.84       632

   micro avg       0.84      0.84      0.84      2860
   macro avg       0.83      0.82      0.83      2860
weighted avg       0.84      0.84      0.84      2860

Result for RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',
            max_depth=None, max_features='auto', max_leaf_nodes=None,
            min_impurity_decrease=0.0, min_impurity_split=None,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=None,
            oob_score=False, random_state=1234, verbose=0,
            warm_start=False)
0.8985574865180244
[[1072   29   32   33]
 [  60  625   13    8]
 [  31    8  299   18]
 [  46   16    7  563]]
              precision    recall  f1-score   support

        N-MF       0.89      0.92      0.90      1166
        N-MM       0.92      0.89      0.90       706
        N-NE       0.85      0.84      0.85       356
        N-SE       0.91      0.89      0.90       632

   micro avg       0.89      0.89      0.89      2860
   macro avg       0.89      0.88      0.89      2860
weighted avg       0.90      0.89      0.89      2860

Result for AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,
          learning_rate=1.0, n_estimators=50, random_state=None)
0.7272927708527588
[[1078   38   24   26]
 [ 305  349   41   11]
 [  34   34  265   23]
 [ 186   26   48  372]]
              precision    recall  f1-score   support

        N-MF       0.67      0.92      0.78      1166
        N-MM       0.78      0.49      0.61       706
        N-NE       0.70      0.74      0.72       356
        N-SE       0.86      0.59      0.70       632

   micro avg       0.72      0.72      0.72      2860
   macro avg       0.75      0.69      0.70      2860
weighted avg       0.74      0.72      0.71      2860

Result for LinearDiscriminantAnalysis(n_components=None, priors=None, shrinkage=None,
              solver='svd', store_covariance=False, tol=0.0001)
0.8674583919506198
[[1117   21    6   22]
 [  51  646    3    6]
 [ 142   20  178   16]
 [  70   14    1  547]]
              precision    recall  f1-score   support

        N-MF       0.81      0.96      0.88      1166
        N-MM       0.92      0.92      0.92       706
        N-NE       0.95      0.50      0.65       356
        N-SE       0.93      0.87      0.89       632

   micro avg       0.87      0.87      0.87      2860
   macro avg       0.90      0.81      0.84      2860
weighted avg       0.88      0.87      0.86      2860

Result for QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
               store_covariance=False, store_covariances=None, tol=0.0001)
0.8912280594133911
[[1106   25   14   21]
 [  49  645    6    6]
 [  91   12  241   12]
 [  56   11    5  560]]
              precision    recall  f1-score   support

        N-MF       0.85      0.95      0.90      1166
        N-MM       0.93      0.91      0.92       706
        N-NE       0.91      0.68      0.77       356
        N-SE       0.93      0.89      0.91       632

   micro avg       0.89      0.89      0.89      2860
   macro avg       0.91      0.86      0.88      2860
weighted avg       0.90      0.89      0.89      2860

Result for LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,
     intercept_scaling=1, loss='squared_hinge', max_iter=1000,
     multi_class='ovr', penalty='l2', random_state=1234, tol=0.0001,
     verbose=0)
0.7985515566297514
[[1118   26    7   15]
 [ 221  467   13    5]
 [  81   50  208   17]
 [ 127   13    8  484]]
              precision    recall  f1-score   support

        N-MF       0.72      0.96      0.82      1166
        N-MM       0.84      0.66      0.74       706
        N-NE       0.88      0.58      0.70       356
        N-SE       0.93      0.77      0.84       632

   micro avg       0.80      0.80      0.80      2860
   macro avg       0.84      0.74      0.78      2860
weighted avg       0.82      0.80      0.79      2860

Result for MLPClassifier(activation='relu', alpha=1, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(100,), learning_rate='constant',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,
       random_state=None, shuffle=True, solver='adam', tol=0.0001,
       validation_fraction=0.1, verbose=False, warm_start=False)
0.49090133620149085
[[1112   34    2   18]
 [ 590   56    9   51]
 [  87   23  175   71]
 [ 496   48   14   74]]
              precision    recall  f1-score   support

        N-MF       0.49      0.95      0.64      1166
        N-MM       0.35      0.08      0.13       706
        N-NE       0.88      0.49      0.63       356
        N-SE       0.35      0.12      0.17       632

   micro avg       0.50      0.50      0.50      2860
   macro avg       0.51      0.41      0.39      2860
weighted avg       0.47      0.50      0.41      2860

Result for GradientBoostingClassifier(criterion='friedman_mse', init=None,
              learning_rate=0.1, loss='deviance', max_depth=5,
              max_features=None, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=1, min_samples_split=2,
              min_weight_fraction_leaf=0.0, n_estimators=100,
              n_iter_no_change=None, presort='auto', random_state=1234,
              subsample=1.0, tol=0.0001, validation_fraction=0.1,
              verbose=0, warm_start=False)
0.8950535019057433
[[1072   35   30   29]
 [  60  623   15    8]
 [  31   13  298   14]
 [  55   15    8  554]]
              precision    recall  f1-score   support

        N-MF       0.88      0.92      0.90      1166
        N-MM       0.91      0.88      0.90       706
        N-NE       0.85      0.84      0.84       356
        N-SE       0.92      0.88      0.90       632

   micro avg       0.89      0.89      0.89      2860
   macro avg       0.89      0.88      0.88      2860
weighted avg       0.89      0.89      0.89      2860

