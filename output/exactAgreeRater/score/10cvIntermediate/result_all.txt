Result for GaussianNB(priors=None, var_smoothing=1e-09)
0.6458172266102035
[[1830  575    3  137]
 [ 444  540    9  292]
 [   7    0  309   20]
 [ 111  107   32  483]]
              precision    recall  f1-score   support

        I-MF       0.77      0.72      0.74      2545
        I-MM       0.44      0.42      0.43      1285
        I-NE       0.88      0.92      0.90       336
        I-SE       0.52      0.66      0.58       733

   micro avg       0.65      0.65      0.65      4899
   macro avg       0.65      0.68      0.66      4899
weighted avg       0.65      0.65      0.65      4899

Result for LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='warn',
          n_jobs=None, penalty='l2', random_state=1234, solver='warn',
          tol=0.0001, verbose=0, warm_start=False)
0.6625995731220754
[[2537    7    0    1]
 [1022  263    0    0]
 [  36   58  181   61]
 [ 359  109    0  265]]
              precision    recall  f1-score   support

        I-MF       0.64      1.00      0.78      2545
        I-MM       0.60      0.20      0.31      1285
        I-NE       1.00      0.54      0.70       336
        I-SE       0.81      0.36      0.50       733

   micro avg       0.66      0.66      0.66      4899
   macro avg       0.76      0.53      0.57      4899
weighted avg       0.68      0.66      0.61      4899

Result for DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,
            max_features=None, max_leaf_nodes=None,
            min_impurity_decrease=0.0, min_impurity_split=None,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, presort=False, random_state=None,
            splitter='best')
0.8930623495482045
[[2349  152    4   40]
 [ 160 1071    4   50]
 [  12    6  308   10]
 [  41   51   12  629]]
              precision    recall  f1-score   support

        I-MF       0.92      0.92      0.92      2545
        I-MM       0.84      0.83      0.84      1285
        I-NE       0.94      0.92      0.93       336
        I-SE       0.86      0.86      0.86       733

   micro avg       0.89      0.89      0.89      4899
   macro avg       0.89      0.88      0.89      4899
weighted avg       0.89      0.89      0.89      4899

Result for RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',
            max_depth=None, max_features='auto', max_leaf_nodes=None,
            min_impurity_decrease=0.0, min_impurity_split=None,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=None,
            oob_score=False, random_state=1234, verbose=0,
            warm_start=False)
0.9220185435503059
[[2420  101    5   19]
 [ 126 1136    2   21]
 [   5    6  319    6]
 [  33   45   10  645]]
              precision    recall  f1-score   support

        I-MF       0.94      0.95      0.94      2545
        I-MM       0.88      0.88      0.88      1285
        I-NE       0.95      0.95      0.95       336
        I-SE       0.93      0.88      0.91       733

   micro avg       0.92      0.92      0.92      4899
   macro avg       0.93      0.92      0.92      4899
weighted avg       0.92      0.92      0.92      4899

Result for AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,
          learning_rate=1.0, n_estimators=50, random_state=None)
0.7858710634255747
[[2306  221    3   15]
 [ 440  792    5   48]
 [  10    3  311   12]
 [  53  131   18  531]]
              precision    recall  f1-score   support

        I-MF       0.82      0.91      0.86      2545
        I-MM       0.69      0.62      0.65      1285
        I-NE       0.92      0.93      0.92       336
        I-SE       0.88      0.72      0.79       733

   micro avg       0.80      0.80      0.80      4899
   macro avg       0.83      0.79      0.81      4899
weighted avg       0.80      0.80      0.80      4899

Result for LinearDiscriminantAnalysis(n_components=None, priors=None, shrinkage=None,
              solver='svd', store_covariance=False, tol=0.0001)
0.9028158972230498
[[2367  135    1   42]
 [  69 1186    0   30]
 [  14   96  199   27]
 [  25   37    0  671]]
              precision    recall  f1-score   support

        I-MF       0.96      0.93      0.94      2545
        I-MM       0.82      0.92      0.87      1285
        I-NE       0.99      0.59      0.74       336
        I-SE       0.87      0.92      0.89       733

   micro avg       0.90      0.90      0.90      4899
   macro avg       0.91      0.84      0.86      4899
weighted avg       0.91      0.90      0.90      4899

Result for QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
               store_covariance=False, store_covariances=None, tol=0.0001)
0.9222018138629371
[[2387  128    3   27]
 [  95 1169    0   21]
 [  10    1  312   13]
 [  33   39    5  656]]
              precision    recall  f1-score   support

        I-MF       0.95      0.94      0.94      2545
        I-MM       0.87      0.91      0.89      1285
        I-NE       0.97      0.93      0.95       336
        I-SE       0.91      0.89      0.90       733

   micro avg       0.92      0.92      0.92      4899
   macro avg       0.93      0.92      0.92      4899
weighted avg       0.92      0.92      0.92      4899

Result for LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,
     intercept_scaling=1, loss='squared_hinge', max_iter=1000,
     multi_class='ovr', penalty='l2', random_state=1234, tol=0.0001,
     verbose=0)
0.8983343717644366
[[2467   60    2   16]
 [ 249 1017    0   19]
 [  15   36  268   17]
 [  42   40    4  647]]
              precision    recall  f1-score   support

        I-MF       0.89      0.97      0.93      2545
        I-MM       0.88      0.79      0.83      1285
        I-NE       0.98      0.80      0.88       336
        I-SE       0.93      0.88      0.90       733

   micro avg       0.90      0.90      0.90      4899
   macro avg       0.92      0.86      0.89      4899
weighted avg       0.90      0.90      0.90      4899

Result for MLPClassifier(activation='relu', alpha=1, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(100,), learning_rate='constant',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,
       random_state=None, shuffle=True, solver='adam', tol=0.0001,
       validation_fraction=0.1, verbose=False, warm_start=False)
0.5495247917892473
[[2542    3    0    0]
 [1252   33    0    0]
 [  40  130  116   50]
 [ 613  120    0    0]]
              precision    recall  f1-score   support

        I-MF       0.57      1.00      0.73      2545
        I-MM       0.12      0.03      0.04      1285
        I-NE       1.00      0.35      0.51       336
        I-SE       0.00      0.00      0.00       733

   micro avg       0.55      0.55      0.55      4899
   macro avg       0.42      0.34      0.32      4899
weighted avg       0.40      0.55      0.42      4899

Result for GradientBoostingClassifier(criterion='friedman_mse', init=None,
              learning_rate=0.1, loss='deviance', max_depth=5,
              max_features=None, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=1, min_samples_split=2,
              min_weight_fraction_leaf=0.0, n_estimators=100,
              n_iter_no_change=None, presort='auto', random_state=1234,
              subsample=1.0, tol=0.0001, validation_fraction=0.1,
              verbose=0, warm_start=False)
0.9246666816053599
[[2414  109    4   18]
 [ 125 1132    5   23]
 [   7    5  317    7]
 [  31   40   10  652]]
              precision    recall  f1-score   support

        I-MF       0.94      0.95      0.94      2545
        I-MM       0.88      0.88      0.88      1285
        I-NE       0.94      0.94      0.94       336
        I-SE       0.93      0.89      0.91       733

   micro avg       0.92      0.92      0.92      4899
   macro avg       0.92      0.92      0.92      4899
weighted avg       0.92      0.92      0.92      4899

