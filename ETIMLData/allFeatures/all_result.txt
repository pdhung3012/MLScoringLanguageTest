Result for GaussianNB(priors=None)
0.5789497851566907
[[5491 1272   19  388]
 [1648 2114  186 1581]
 [  34  129 1537  590]
 [ 367 1094  714 1905]]
             precision    recall  f1-score   support

       I-MF       0.73      0.77      0.75      7170
       I-MM       0.46      0.38      0.42      5529
       I-NE       0.63      0.67      0.65      2290
       I-SE       0.43      0.47      0.45      4080

avg / total       0.57      0.58      0.57     19069

Result for LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=1234, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
0.6931671353840245
[[6304  789   13   64]
 [1510 3284   83  652]
 [  63  136 1483  608]
 [ 432 1175  324 2149]]
             precision    recall  f1-score   support

       I-MF       0.76      0.88      0.81      7170
       I-MM       0.61      0.59      0.60      5529
       I-NE       0.78      0.65      0.71      2290
       I-SE       0.62      0.53      0.57      4080

avg / total       0.69      0.69      0.69     19069

Result for DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,
            max_features=None, max_leaf_nodes=None,
            min_impurity_decrease=0.0, min_impurity_split=None,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, presort=False, random_state=None,
            splitter='best')
0.804447440836241
[[6524  555   22   69]
 [ 492 4226   40  771]
 [  12   33 1889  356]
 [  89  847  389 2755]]
             precision    recall  f1-score   support

       I-MF       0.92      0.91      0.91      7170
       I-MM       0.75      0.76      0.76      5529
       I-NE       0.81      0.82      0.82      2290
       I-SE       0.70      0.68      0.69      4080

avg / total       0.81      0.81      0.81     19069
Result for RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',
            max_depth=None, max_features='auto', max_leaf_nodes=None,
            min_impurity_decrease=0.0, min_impurity_split=None,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=1,
            oob_score=False, random_state=1234, verbose=0,
            warm_start=False)
0.8131520476556521
[[6584  536    8   42]
 [ 494 4225   27  783]
 [   8   41 1887  354]
 [  65  815  372 2828]]
             precision    recall  f1-score   support

       I-MF       0.92      0.92      0.92      7170
       I-MM       0.75      0.76      0.76      5529
       I-NE       0.82      0.82      0.82      2290
       I-SE       0.71      0.69      0.70      4080

avg / total       0.81      0.81      0.81     19069

Result for AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,
          learning_rate=1.0, n_estimators=50, random_state=None)
0.6699879936457663
[[6000 1099    5   66]
 [1552 2995   57  925]
 [  35   72 1843  340]
 [ 371 1337  455 1917]]
             precision    recall  f1-score   support

       I-MF       0.75      0.84      0.79      7170
       I-MM       0.54      0.54      0.54      5529
       I-NE       0.78      0.80      0.79      2290
       I-SE       0.59      0.47      0.52      4080

avg / total       0.66      0.67      0.66     19069
Result for LinearDiscriminantAnalysis(n_components=None, priors=None, shrinkage=None,
              solver='svd', store_covariance=False, tol=0.0001)
0.8887729583007543
[[6606  525    9   30]
 [ 210 4818   17  484]
 [  22   31 2050  187]
 [  28  383  205 3464]]
             precision    recall  f1-score   support

       I-MF       0.96      0.92      0.94      7170
       I-MM       0.84      0.87      0.85      5529
       I-NE       0.90      0.90      0.90      2290
       I-SE       0.83      0.85      0.84      4080

avg / total       0.89      0.89      0.89     19069

Result for QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
               store_covariance=False, store_covariances=None, tol=0.0001)
0.8331321727924568
[[6674  382   43   71]
 [ 557 4377   47  548]
 [  12    5 1696  577]
 [  49  716  184 3131]]
             precision    recall  f1-score   support

       I-MF       0.92      0.93      0.92      7170
       I-MM       0.80      0.79      0.80      5529
       I-NE       0.86      0.74      0.80      2290
       I-SE       0.72      0.77      0.74      4080

avg / total       0.83      0.83      0.83     19069

Result for LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,
     intercept_scaling=1, loss='squared_hinge', max_iter=1000,
     multi_class='ovr', penalty='l2', random_state=1234, tol=0.0001,
     verbose=0)
0.7635953528476024
[[6329  728   17   96]
 [1178 3672   73  606]
 [  53  141 1818  278]
 [ 334  758  250 2738]]
             precision    recall  f1-score   support

       I-MF       0.80      0.88      0.84      7170
       I-MM       0.69      0.66      0.68      5529
       I-NE       0.84      0.79      0.82      2290
       I-SE       0.74      0.67      0.70      4080

avg / total       0.76      0.76      0.76     19069

Result for MLPClassifier(activation='relu', alpha=1, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(100,), learning_rate='constant',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
0.6322829515822581
[[5971 1086    5  108]
 [1512 3043   60  914]
 [  46  201 1344  699]
 [ 371 1595  350 1764]]
             precision    recall  f1-score   support

       I-MF       0.76      0.83      0.79      7170
       I-MM       0.51      0.55      0.53      5529
       I-NE       0.76      0.59      0.66      2290
       I-SE       0.51      0.43      0.47      4080

avg / total       0.63      0.64      0.63     19069

Result for GradientBoostingClassifier(criterion='friedman_mse', init=None,
              learning_rate=0.1, loss='deviance', max_depth=5,
              max_features=None, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=1, min_samples_split=2,
              min_weight_fraction_leaf=0.0, n_estimators=100,
              presort='auto', random_state=1234, subsample=1.0, verbose=0,
              warm_start=False)
0.8101099335248552
[[6404  702   10   54]
 [ 656 4291   17  565]
 [  11   51 1908  320]
 [ 151  751  296 2882]]
             precision    recall  f1-score   support

       I-MF       0.89      0.89      0.89      7170
       I-MM       0.74      0.78      0.76      5529
       I-NE       0.86      0.83      0.84      2290
       I-SE       0.75      0.71      0.73      4080

avg / total       0.81      0.81      0.81     19069
