Result for GaussianNB(priors=None, var_smoothing=1e-09)
[[11  0  0  0]
 [ 0  9  0  1]
 [ 0  0 27  4]
 [ 1  1  6 30]]
              precision    recall  f1-score   support

        A-MF       0.92      1.00      0.96        11
        A-MM       0.90      0.90      0.90        10
        A-NE       0.82      0.87      0.84        31
        A-SE       0.86      0.79      0.82        38

   micro avg       0.86      0.86      0.86        90
   macro avg       0.87      0.89      0.88        90
weighted avg       0.86      0.86      0.85        90

Result for LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='warn',
          n_jobs=None, penalty='l2', random_state=1234, solver='warn',
          tol=0.0001, verbose=0, warm_start=False)
[[11  0  0  0]
 [ 0 10  0  0]
 [ 0  0 22  9]
 [ 0  0  2 36]]
              precision    recall  f1-score   support

        A-MF       1.00      1.00      1.00        11
        A-MM       1.00      1.00      1.00        10
        A-NE       0.92      0.71      0.80        31
        A-SE       0.80      0.95      0.87        38

   micro avg       0.88      0.88      0.88        90
   macro avg       0.93      0.91      0.92        90
weighted avg       0.89      0.88      0.88        90

Result for DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,
            max_features=None, max_leaf_nodes=None,
            min_impurity_decrease=0.0, min_impurity_split=None,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, presort=False, random_state=None,
            splitter='best')
[[11  0  0  0]
 [ 0  8  0  2]
 [ 0  0 31  0]
 [ 0  0  0 38]]
              precision    recall  f1-score   support

        A-MF       1.00      1.00      1.00        11
        A-MM       1.00      0.80      0.89        10
        A-NE       1.00      1.00      1.00        31
        A-SE       0.95      1.00      0.97        38

   micro avg       0.98      0.98      0.98        90
   macro avg       0.99      0.95      0.97        90
weighted avg       0.98      0.98      0.98        90

Result for RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',
            max_depth=None, max_features='auto', max_leaf_nodes=None,
            min_impurity_decrease=0.0, min_impurity_split=None,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=None,
            oob_score=False, random_state=1234, verbose=0,
            warm_start=False)
[[11  0  0  0]
 [ 0  9  0  1]
 [ 0  0 31  0]
 [ 0  0  1 37]]
              precision    recall  f1-score   support

        A-MF       1.00      1.00      1.00        11
        A-MM       1.00      0.90      0.95        10
        A-NE       0.97      1.00      0.98        31
        A-SE       0.97      0.97      0.97        38

   micro avg       0.98      0.98      0.98        90
   macro avg       0.99      0.97      0.98        90
weighted avg       0.98      0.98      0.98        90

Result for AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,
          learning_rate=1.0, n_estimators=50, random_state=None)
[[10  0  0  1]
 [ 0  8  0  2]
 [ 0  0 31  0]
 [ 0  0  2 36]]
              precision    recall  f1-score   support

        A-MF       1.00      0.91      0.95        11
        A-MM       1.00      0.80      0.89        10
        A-NE       0.94      1.00      0.97        31
        A-SE       0.92      0.95      0.94        38

   micro avg       0.94      0.94      0.94        90
   macro avg       0.97      0.91      0.94        90
weighted avg       0.95      0.94      0.94        90

Result for LinearDiscriminantAnalysis(n_components=None, priors=None, shrinkage=None,
              solver='svd', store_covariance=False, tol=0.0001)
[[11  0  0  0]
 [ 0 10  0  0]
 [ 0  0 31  0]
 [ 0  0  0 38]]
              precision    recall  f1-score   support

        A-MF       1.00      1.00      1.00        11
        A-MM       1.00      1.00      1.00        10
        A-NE       1.00      1.00      1.00        31
        A-SE       1.00      1.00      1.00        38

   micro avg       1.00      1.00      1.00        90
   macro avg       1.00      1.00      1.00        90
weighted avg       1.00      1.00      1.00        90

Result for QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
               store_covariance=False, store_covariances=None, tol=0.0001)
[[10  1  0  0]
 [ 0 10  0  0]
 [ 0  0 31  0]
 [ 0 36  2  0]]
              precision    recall  f1-score   support

        A-MF       1.00      0.91      0.95        11
        A-MM       0.21      1.00      0.35        10
        A-NE       0.94      1.00      0.97        31
        A-SE       0.00      0.00      0.00        38

   micro avg       0.57      0.57      0.57        90
   macro avg       0.54      0.73      0.57        90
weighted avg       0.47      0.57      0.49        90

Result for LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,
     intercept_scaling=1, loss='squared_hinge', max_iter=1000,
     multi_class='ovr', penalty='l2', random_state=1234, tol=0.0001,
     verbose=0)
[[11  0  0  0]
 [ 0 10  0  0]
 [ 0  0 31  0]
 [ 0  0  0 38]]
              precision    recall  f1-score   support

        A-MF       1.00      1.00      1.00        11
        A-MM       1.00      1.00      1.00        10
        A-NE       1.00      1.00      1.00        31
        A-SE       1.00      1.00      1.00        38

   micro avg       1.00      1.00      1.00        90
   macro avg       1.00      1.00      1.00        90
weighted avg       1.00      1.00      1.00        90

Result for MLPClassifier(activation='relu', alpha=1, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(100,), learning_rate='constant',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,
       random_state=None, shuffle=True, solver='adam', tol=0.0001,
       validation_fraction=0.1, verbose=False, warm_start=False)
[[11  0  0  0]
 [ 5  0  0  5]
 [ 0  0 17 14]
 [ 0  0  4 34]]
              precision    recall  f1-score   support

        A-MF       0.69      1.00      0.81        11
        A-MM       0.00      0.00      0.00        10
        A-NE       0.81      0.55      0.65        31
        A-SE       0.64      0.89      0.75        38

   micro avg       0.69      0.69      0.69        90
   macro avg       0.53      0.61      0.55        90
weighted avg       0.63      0.69      0.64        90

Result for GradientBoostingClassifier(criterion='friedman_mse', init=None,
              learning_rate=0.1, loss='deviance', max_depth=5,
              max_features=None, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=1, min_samples_split=2,
              min_weight_fraction_leaf=0.0, n_estimators=100,
              n_iter_no_change=None, presort='auto', random_state=1234,
              subsample=1.0, tol=0.0001, validation_fraction=0.1,
              verbose=0, warm_start=False)
[[11  0  0  0]
 [ 0 10  0  0]
 [ 0  0 31  0]
 [ 0  0  0 38]]
              precision    recall  f1-score   support

        A-MF       1.00      1.00      1.00        11
        A-MM       1.00      1.00      1.00        10
        A-NE       1.00      1.00      1.00        31
        A-SE       1.00      1.00      1.00        38

   micro avg       1.00      1.00      1.00        90
   macro avg       1.00      1.00      1.00        90
weighted avg       1.00      1.00      1.00        90

