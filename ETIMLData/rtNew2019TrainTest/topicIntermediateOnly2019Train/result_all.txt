Result for GaussianNB(priors=None, var_smoothing=1e-09)
[[12  8  1  7  0  5]
 [14  4  0 12  0  3]
 [ 2  2  0  6  0  1]
 [10  2  2 19  0  7]
 [ 0  0  0 13  0  5]
 [ 4  0  0  9  0  5]]
                precision    recall  f1-score   support

       ANIMALS       0.29      0.36      0.32        33
COMMUNICATIONS       0.25      0.12      0.16        33
    DIRECTIONS       0.00      0.00      0.00        11
   POP_CULTURE       0.29      0.47      0.36        40
       THEATER       0.00      0.00      0.00        18
        TRAVEL       0.19      0.28      0.23        18

     micro avg       0.26      0.26      0.26       153
     macro avg       0.17      0.21      0.18       153
  weighted avg       0.21      0.26      0.22       153

Result for LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='warn',
          n_jobs=None, penalty='l2', random_state=1234, solver='warn',
          tol=0.0001, verbose=0, warm_start=False)
[[15  0  0 13  0  5]
 [17  0  0 11  0  5]
 [ 3  0  0  8  0  0]
 [13  0  0 20  0  7]
 [ 0  0  0  9  0  9]
 [ 5  0  0  4  0  9]]
                precision    recall  f1-score   support

       ANIMALS       0.28      0.45      0.35        33
COMMUNICATIONS       0.00      0.00      0.00        33
    DIRECTIONS       0.00      0.00      0.00        11
   POP_CULTURE       0.31      0.50      0.38        40
       THEATER       0.00      0.00      0.00        18
        TRAVEL       0.26      0.50      0.34        18

     micro avg       0.29      0.29      0.29       153
     macro avg       0.14      0.24      0.18       153
  weighted avg       0.17      0.29      0.21       153

Result for DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,
            max_features=None, max_leaf_nodes=None,
            min_impurity_decrease=0.0, min_impurity_split=None,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, presort=False, random_state=None,
            splitter='best')
[[19  3  0  6  2  3]
 [20  3  0  5  3  2]
 [ 7  1  0  3  0  0]
 [23  4  1  5  5  2]
 [17  0  0  1  0  0]
 [13  2  0  2  1  0]]
                precision    recall  f1-score   support

       ANIMALS       0.19      0.58      0.29        33
COMMUNICATIONS       0.23      0.09      0.13        33
    DIRECTIONS       0.00      0.00      0.00        11
   POP_CULTURE       0.23      0.12      0.16        40
       THEATER       0.00      0.00      0.00        18
        TRAVEL       0.00      0.00      0.00        18

     micro avg       0.18      0.18      0.18       153
     macro avg       0.11      0.13      0.10       153
  weighted avg       0.15      0.18      0.13       153

Result for RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',
            max_depth=None, max_features='auto', max_leaf_nodes=None,
            min_impurity_decrease=0.0, min_impurity_split=None,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=None,
            oob_score=False, random_state=1234, verbose=0,
            warm_start=False)
[[22  4  0  6  0  1]
 [21  3  0  9  0  0]
 [ 8  3  0  0  0  0]
 [28  3  0  8  0  1]
 [15  3  0  0  0  0]
 [17  0  0  1  0  0]]
                precision    recall  f1-score   support

       ANIMALS       0.20      0.67      0.31        33
COMMUNICATIONS       0.19      0.09      0.12        33
    DIRECTIONS       0.00      0.00      0.00        11
   POP_CULTURE       0.33      0.20      0.25        40
       THEATER       0.00      0.00      0.00        18
        TRAVEL       0.00      0.00      0.00        18

     micro avg       0.22      0.22      0.22       153
     macro avg       0.12      0.16      0.11       153
  weighted avg       0.17      0.22      0.16       153

Result for AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,
          learning_rate=1.0, n_estimators=50, random_state=None)
[[16  2  1  0  8  0  6]
 [ 0  0  0  0  0  0  0]
 [ 9 13  3  0  8  0  0]
 [ 6  4  0  1  0  0  0]
 [ 9 18  1  2  9  0  1]
 [10  5  1  0  0  0  2]
 [ 5  5  1  0  1  0  6]]
                precision    recall  f1-score   support

       ANIMALS       0.29      0.48      0.36        33
       CAREERS       0.00      0.00      0.00         0
COMMUNICATIONS       0.43      0.09      0.15        33
    DIRECTIONS       0.33      0.09      0.14        11
   POP_CULTURE       0.35      0.23      0.27        40
       THEATER       0.00      0.00      0.00        18
        TRAVEL       0.40      0.33      0.36        18

     micro avg       0.23      0.23      0.23       153
     macro avg       0.26      0.18      0.18       153
  weighted avg       0.32      0.23      0.24       153

Result for LinearDiscriminantAnalysis(n_components=None, priors=None, shrinkage=None,
              solver='svd', store_covariance=False, tol=0.0001)
[[ 2 18  1  4  2  1  0  5]
 [ 0  0  0  0  0  0  0  0]
 [ 3 20  1  3  1  1  1  3]
 [ 0  9  1  0  0  1  0  0]
 [ 1 29  0  4  2  0  0  4]
 [ 0  0  0  0  0  0  0  0]
 [ 0 18  0  0  0  0  0  0]
 [ 0 14  0  1  0  0  0  3]]
                precision    recall  f1-score   support

       ANIMALS       0.33      0.06      0.10        33
       CAREERS       0.00      0.00      0.00         0
COMMUNICATIONS       0.33      0.03      0.06        33
    DIRECTIONS       0.00      0.00      0.00        11
   POP_CULTURE       0.40      0.05      0.09        40
       SCIENCE       0.00      0.00      0.00         0
       THEATER       0.00      0.00      0.00        18
        TRAVEL       0.20      0.17      0.18        18

     micro avg       0.05      0.05      0.05       153
     macro avg       0.16      0.04      0.05       153
  weighted avg       0.27      0.05      0.08       153

Result for QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
               store_covariance=False, store_covariances=None, tol=0.0001)
[[20  5  1  1  5  0  1]
 [20  5  1  3  4  0  0]
 [ 7  0  1  0  3  0  0]
 [28  4  0  4  4  0  0]
 [ 0  0  0  0  0  0  0]
 [17  0  0  0  1  0  0]
 [16  0  0  1  0  0  1]]
                precision    recall  f1-score   support

       ANIMALS       0.19      0.61      0.28        33
COMMUNICATIONS       0.36      0.15      0.21        33
    DIRECTIONS       0.33      0.09      0.14        11
   POP_CULTURE       0.44      0.10      0.16        40
       SCIENCE       0.00      0.00      0.00         0
       THEATER       0.00      0.00      0.00        18
        TRAVEL       0.50      0.06      0.10        18

     micro avg       0.20      0.20      0.20       153
     macro avg       0.26      0.14      0.13       153
  weighted avg       0.32      0.20      0.17       153

Result for LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,
     intercept_scaling=1, loss='squared_hinge', max_iter=1000,
     multi_class='ovr', penalty='l2', random_state=1234, tol=0.0001,
     verbose=0)
[[22  4  0  4  0  3]
 [22  4  0  4  0  3]
 [ 8  2  0  1  0  0]
 [29  5  0  2  0  4]
 [17  1  0  0  0  0]
 [15  1  0  0  0  2]]
                precision    recall  f1-score   support

       ANIMALS       0.19      0.67      0.30        33
COMMUNICATIONS       0.24      0.12      0.16        33
    DIRECTIONS       0.00      0.00      0.00        11
   POP_CULTURE       0.18      0.05      0.08        40
       THEATER       0.00      0.00      0.00        18
        TRAVEL       0.17      0.11      0.13        18

     micro avg       0.20      0.20      0.20       153
     macro avg       0.13      0.16      0.11       153
  weighted avg       0.16      0.20      0.14       153

Result for MLPClassifier(activation='relu', alpha=1, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(100,), learning_rate='constant',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,
       random_state=None, shuffle=True, solver='adam', tol=0.0001,
       validation_fraction=0.1, verbose=False, warm_start=False)
[[ 0  0  0 33  0  0]
 [ 0  0  0 33  0  0]
 [ 0  0  0 11  0  0]
 [ 0  0  0 40  0  0]
 [ 0  0  0 18  0  0]
 [ 0  0  0 18  0  0]]
                precision    recall  f1-score   support

       ANIMALS       0.00      0.00      0.00        33
COMMUNICATIONS       0.00      0.00      0.00        33
    DIRECTIONS       0.00      0.00      0.00        11
   POP_CULTURE       0.26      1.00      0.41        40
       THEATER       0.00      0.00      0.00        18
        TRAVEL       0.00      0.00      0.00        18

     micro avg       0.26      0.26      0.26       153
     macro avg       0.04      0.17      0.07       153
  weighted avg       0.07      0.26      0.11       153

Result for GradientBoostingClassifier(criterion='friedman_mse', init=None,
              learning_rate=0.1, loss='deviance', max_depth=5,
              max_features=None, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=1, min_samples_split=2,
              min_weight_fraction_leaf=0.0, n_estimators=100,
              n_iter_no_change=None, presort='auto', random_state=1234,
              subsample=1.0, tol=0.0001, validation_fraction=0.1,
              verbose=0, warm_start=False)
[[19  1  7  0  4  0  1  1]
 [ 0  0  0  0  0  0  0  0]
 [17  1  7  0  4  1  1  2]
 [ 7  0  4  0  0  0  0  0]
 [26  0  5  0  6  1  1  1]
 [ 0  0  0  0  0  0  0  0]
 [17  0  0  0  0  0  0  1]
 [14  0  0  0  1  0  0  3]]
                precision    recall  f1-score   support

       ANIMALS       0.19      0.58      0.29        33
       CAREERS       0.00      0.00      0.00         0
COMMUNICATIONS       0.30      0.21      0.25        33
    DIRECTIONS       0.00      0.00      0.00        11
   POP_CULTURE       0.40      0.15      0.22        40
       SCIENCE       0.00      0.00      0.00         0
       THEATER       0.00      0.00      0.00        18
        TRAVEL       0.38      0.17      0.23        18

     micro avg       0.23      0.23      0.23       153
     macro avg       0.16      0.14      0.12       153
  weighted avg       0.26      0.23      0.20       153

