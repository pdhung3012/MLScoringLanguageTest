Result for GaussianNB(priors=None, var_smoothing=1e-09)
0.9631187313635131
[[192   5   1   1]
 [  0  31   0   0]
 [  1   1  59   1]
 [  4   0   0  28]]
              precision    recall  f1-score   support

        N-MF       0.97      0.96      0.97       199
        N-MM       0.84      1.00      0.91        31
        N-NE       0.98      0.95      0.97        62
        N-SE       0.93      0.88      0.90        32

   micro avg       0.96      0.96      0.96       324
   macro avg       0.93      0.95      0.94       324
weighted avg       0.96      0.96      0.96       324

Result for LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='warn',
          n_jobs=None, penalty='l2', random_state=1234, solver='warn',
          tol=0.0001, verbose=0, warm_start=False)
0.8239634724857684
[[199   0   0   0]
 [ 25   5   1   0]
 [  6   0  56   0]
 [ 23   0   2   7]]
              precision    recall  f1-score   support

        N-MF       0.79      1.00      0.88       199
        N-MM       1.00      0.16      0.28        31
        N-NE       0.95      0.90      0.93        62
        N-SE       1.00      0.22      0.36        32

   micro avg       0.82      0.82      0.82       324
   macro avg       0.93      0.57      0.61       324
weighted avg       0.86      0.82      0.78       324

Result for DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,
            max_features=None, max_leaf_nodes=None,
            min_impurity_decrease=0.0, min_impurity_split=None,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, presort=False, random_state=None,
            splitter='best')
0.969552554892925
[[195   1   2   1]
 [  0  29   1   1]
 [  3   0  59   0]
 [  1   1   0  30]]
              precision    recall  f1-score   support

        N-MF       0.98      0.98      0.98       199
        N-MM       0.94      0.94      0.94        31
        N-NE       0.95      0.95      0.95        62
        N-SE       0.94      0.94      0.94        32

   micro avg       0.97      0.97      0.97       324
   macro avg       0.95      0.95      0.95       324
weighted avg       0.97      0.97      0.97       324

Result for RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',
            max_depth=None, max_features='auto', max_leaf_nodes=None,
            min_impurity_decrease=0.0, min_impurity_split=None,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=None,
            oob_score=False, random_state=1234, verbose=0,
            warm_start=False)
0.9854621848739497
[[199   0   0   0]
 [  0  30   0   1]
 [  3   0  59   0]
 [  1   0   0  31]]
              precision    recall  f1-score   support

        N-MF       0.98      1.00      0.99       199
        N-MM       1.00      0.97      0.98        31
        N-NE       1.00      0.95      0.98        62
        N-SE       0.97      0.97      0.97        32

   micro avg       0.98      0.98      0.98       324
   macro avg       0.99      0.97      0.98       324
weighted avg       0.98      0.98      0.98       324

Result for AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,
          learning_rate=1.0, n_estimators=50, random_state=None)
0.9689170506912443
[[195   1   1   2]
 [  1  30   0   0]
 [  4   0  58   0]
 [  2   0   2  28]]
              precision    recall  f1-score   support

        N-MF       0.97      0.98      0.97       199
        N-MM       0.97      0.97      0.97        31
        N-NE       0.95      0.94      0.94        62
        N-SE       0.93      0.88      0.90        32

   micro avg       0.96      0.96      0.96       324
   macro avg       0.95      0.94      0.95       324
weighted avg       0.96      0.96      0.96       324

Result for LinearDiscriminantAnalysis(n_components=None, priors=None, shrinkage=None,
              solver='svd', store_covariance=False, tol=0.0001)
0.9631187313635131
[[199   0   0   0]
 [  0  31   0   0]
 [  6   0  56   0]
 [  6   0   0  26]]
              precision    recall  f1-score   support

        N-MF       0.94      1.00      0.97       199
        N-MM       1.00      1.00      1.00        31
        N-NE       1.00      0.90      0.95        62
        N-SE       1.00      0.81      0.90        32

   micro avg       0.96      0.96      0.96       324
   macro avg       0.99      0.93      0.95       324
weighted avg       0.97      0.96      0.96       324

Result for QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
               store_covariance=False, store_covariances=None, tol=0.0001)
0.9689160341555978
[[196   0   0   3]
 [  0  31   0   0]
 [  1   2  58   1]
 [  1   0   0  31]]
              precision    recall  f1-score   support

        N-MF       0.99      0.98      0.99       199
        N-MM       0.94      1.00      0.97        31
        N-NE       1.00      0.94      0.97        62
        N-SE       0.89      0.97      0.93        32

   micro avg       0.98      0.98      0.98       324
   macro avg       0.95      0.97      0.96       324
weighted avg       0.98      0.98      0.98       324

Result for LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,
     intercept_scaling=1, loss='squared_hinge', max_iter=1000,
     multi_class='ovr', penalty='l2', random_state=1234, tol=0.0001,
     verbose=0)
0.9692846977500679
[[199   0   0   0]
 [  0  31   0   0]
 [  5   0  57   0]
 [  4   0   1  27]]
              precision    recall  f1-score   support

        N-MF       0.96      1.00      0.98       199
        N-MM       1.00      1.00      1.00        31
        N-NE       0.98      0.92      0.95        62
        N-SE       1.00      0.84      0.92        32

   micro avg       0.97      0.97      0.97       324
   macro avg       0.98      0.94      0.96       324
weighted avg       0.97      0.97      0.97       324

Result for MLPClassifier(activation='relu', alpha=1, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(100,), learning_rate='constant',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,
       random_state=None, shuffle=True, solver='adam', tol=0.0001,
       validation_fraction=0.1, verbose=False, warm_start=False)
0.911247966928707
[[199   0   0   0]
 [  8  22   1   0]
 [  5   0  57   0]
 [ 12   0   2  18]]
              precision    recall  f1-score   support

        N-MF       0.89      1.00      0.94       199
        N-MM       1.00      0.71      0.83        31
        N-NE       0.95      0.92      0.93        62
        N-SE       1.00      0.56      0.72        32

   micro avg       0.91      0.91      0.91       324
   macro avg       0.96      0.80      0.86       324
weighted avg       0.92      0.91      0.91       324

Result for GradientBoostingClassifier(criterion='friedman_mse', init=None,
              learning_rate=0.1, loss='deviance', max_depth=5,
              max_features=None, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=1, min_samples_split=2,
              min_weight_fraction_leaf=0.0, n_estimators=100,
              n_iter_no_change=None, presort='auto', random_state=1234,
              subsample=1.0, tol=0.0001, validation_fraction=0.1,
              verbose=0, warm_start=False)
0.9814170506912443
[[198   1   0   0]
 [  2  27   1   1]
 [  4   0  58   0]
 [  1   0   0  31]]
              precision    recall  f1-score   support

        N-MF       0.97      0.99      0.98       199
        N-MM       0.96      0.87      0.92        31
        N-NE       0.98      0.94      0.96        62
        N-SE       0.97      0.97      0.97        32

   micro avg       0.97      0.97      0.97       324
   macro avg       0.97      0.94      0.96       324
weighted avg       0.97      0.97      0.97       324

