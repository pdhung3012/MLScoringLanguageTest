Result for GaussianNB(priors=None, var_smoothing=1e-09)
0.6666666666666667
[[59  2  1  0]
 [34 18  1  0]
 [ 0  1  1  1]
 [ 2  2  1  7]]
              precision    recall  f1-score   support

           A       0.62      0.95      0.75        62
          A-       0.78      0.34      0.47        53
           B       0.25      0.33      0.29         3
          B+       0.88      0.58      0.70        12

   micro avg       0.65      0.65      0.65       130
   macro avg       0.63      0.55      0.55       130
weighted avg       0.70      0.65      0.62       130

Result for LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='warn',
          n_jobs=None, penalty='l2', random_state=1234, solver='warn',
          tol=0.0001, verbose=0, warm_start=False)
0.47887820512820517
[[62  0  0  0]
 [53  0  0  0]
 [ 3  0  0  0]
 [12  0  0  0]]
              precision    recall  f1-score   support

           A       0.48      1.00      0.65        62
          A-       0.00      0.00      0.00        53
           B       0.00      0.00      0.00         3
          B+       0.00      0.00      0.00        12

   micro avg       0.48      0.48      0.48       130
   macro avg       0.12      0.25      0.16       130
weighted avg       0.23      0.48      0.31       130

Result for DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,
            max_features=None, max_leaf_nodes=None,
            min_impurity_decrease=0.0, min_impurity_split=None,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, presort=False, random_state=None,
            splitter='best')
0.8823717948717948
[[60  0  1  1]
 [ 2 49  1  1]
 [ 1  1  1  0]
 [ 0  4  0  8]]
              precision    recall  f1-score   support

           A       0.95      0.97      0.96        62
          A-       0.91      0.92      0.92        53
           B       0.33      0.33      0.33         3
          B+       0.80      0.67      0.73        12

   micro avg       0.91      0.91      0.91       130
   macro avg       0.75      0.72      0.73       130
weighted avg       0.91      0.91      0.91       130

Result for RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',
            max_depth=None, max_features='auto', max_leaf_nodes=None,
            min_impurity_decrease=0.0, min_impurity_split=None,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=None,
            oob_score=False, random_state=1234, verbose=0,
            warm_start=False)
0.9144871794871795
[[60  1  0  1]
 [ 1 49  2  1]
 [ 0  3  0  0]
 [ 2  3  0  7]]
              precision    recall  f1-score   support

           A       0.95      0.97      0.96        62
          A-       0.88      0.92      0.90        53
           B       0.00      0.00      0.00         3
          B+       0.78      0.58      0.67        12

   micro avg       0.89      0.89      0.89       130
   macro avg       0.65      0.62      0.63       130
weighted avg       0.88      0.89      0.89       130

Result for AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,
          learning_rate=1.0, n_estimators=50, random_state=None)
0.8011950549450549
[[55  2  0  5]
 [11 37  1  4]
 [ 0  3  0  0]
 [ 3  2  1  6]]
              precision    recall  f1-score   support

           A       0.80      0.89      0.84        62
          A-       0.84      0.70      0.76        53
           B       0.00      0.00      0.00         3
          B+       0.40      0.50      0.44        12

   micro avg       0.75      0.75      0.75       130
   macro avg       0.51      0.52      0.51       130
weighted avg       0.76      0.75      0.75       130

Result for LinearDiscriminantAnalysis(n_components=None, priors=None, shrinkage=None,
              solver='svd', store_covariance=False, tol=0.0001)
0.4716666666666668
[[57  4  1  0]
 [50  2  1  0]
 [ 2  0  0  1]
 [10  0  1  1]]
              precision    recall  f1-score   support

           A       0.48      0.92      0.63        62
          A-       0.33      0.04      0.07        53
           B       0.00      0.00      0.00         3
          B+       0.50      0.08      0.14        12

   micro avg       0.46      0.46      0.46       130
   macro avg       0.33      0.26      0.21       130
weighted avg       0.41      0.46      0.34       130

Result for QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
               store_covariance=False, store_covariances=None, tol=0.0001)
0.9466987179487178
[[59  1  0  2]
 [ 1 52  0  0]
 [ 0  1  0  2]
 [ 0  0  0 12]]
              precision    recall  f1-score   support

           A       0.98      0.95      0.97        62
          A-       0.96      0.98      0.97        53
           B       0.00      0.00      0.00         3
          B+       0.75      1.00      0.86        12

   micro avg       0.95      0.95      0.95       130
   macro avg       0.67      0.73      0.70       130
weighted avg       0.93      0.95      0.94       130

Result for LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,
     intercept_scaling=1, loss='squared_hinge', max_iter=1000,
     multi_class='ovr', penalty='l2', random_state=1234, tol=0.0001,
     verbose=0)
0.4788782051282051
[[62  0  0  0]
 [53  0  0  0]
 [ 3  0  0  0]
 [12  0  0  0]]
              precision    recall  f1-score   support

           A       0.48      1.00      0.65        62
          A-       0.00      0.00      0.00        53
           B       0.00      0.00      0.00         3
          B+       0.00      0.00      0.00        12

   micro avg       0.48      0.48      0.48       130
   macro avg       0.12      0.25      0.16       130
weighted avg       0.23      0.48      0.31       130

Result for MLPClassifier(activation='relu', alpha=1, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(100,), learning_rate='constant',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,
       random_state=None, shuffle=True, solver='adam', tol=0.0001,
       validation_fraction=0.1, verbose=False, warm_start=False)
0.47887820512820517
[[62  0  0  0]
 [53  0  0  0]
 [ 3  0  0  0]
 [12  0  0  0]]
              precision    recall  f1-score   support

           A       0.48      1.00      0.65        62
          A-       0.00      0.00      0.00        53
           B       0.00      0.00      0.00         3
          B+       0.00      0.00      0.00        12

   micro avg       0.48      0.48      0.48       130
   macro avg       0.12      0.25      0.16       130
weighted avg       0.23      0.48      0.31       130

Result for GradientBoostingClassifier(criterion='friedman_mse', init=None,
              learning_rate=0.1, loss='deviance', max_depth=5,
              max_features=None, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=1, min_samples_split=2,
              min_weight_fraction_leaf=0.0, n_estimators=100,
              n_iter_no_change=None, presort='auto', random_state=1234,
              subsample=1.0, tol=0.0001, validation_fraction=0.1,
              verbose=0, warm_start=False)
0.9305128205128204
[[60  1  1  0]
 [ 2 49  1  1]
 [ 1  1  0  1]
 [ 1  1  1  9]]
              precision    recall  f1-score   support

           A       0.94      0.97      0.95        62
          A-       0.94      0.92      0.93        53
           B       0.00      0.00      0.00         3
          B+       0.82      0.75      0.78        12

   micro avg       0.91      0.91      0.91       130
   macro avg       0.67      0.66      0.67       130
weighted avg       0.91      0.91      0.91       130

