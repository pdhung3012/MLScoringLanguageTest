Result for GaussianNB(priors=None)
0.5658396111746034
[[5440 1445    8  277]
 [1508 2475   65 1481]
 [ 213  318  818  941]
 [ 381 1266  356 2077]]
             precision    recall  f1-score   support

       I-MF       0.72      0.76      0.74      7170
       I-MM       0.45      0.45      0.45      5529
       I-NE       0.66      0.36      0.46      2290
       I-SE       0.43      0.51      0.47      4080

avg / total       0.57      0.57      0.56     19069

Result for LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=1234, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
0.5539365655113897
[[6245  830    0   95]
 [2296 2434    2  797]
 [ 360  422  178 1330]
 [ 744 1627    9 1700]]
             precision    recall  f1-score   support

       I-MF       0.65      0.87      0.74      7170
       I-MM       0.46      0.44      0.45      5529
       I-NE       0.94      0.08      0.14      2290
       I-SE       0.43      0.42      0.42      4080

avg / total       0.58      0.55      0.52     19069

Result for DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,
            max_features=None, max_leaf_nodes=None,
            min_impurity_decrease=0.0, min_impurity_split=None,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, presort=False, random_state=None,
            splitter='best')
0.7850438903228895
[[6350  641   57  122]
 [ 555 4075   85  814]
 [  34   96 1783  377]
 [ 128  857  429 2666]]
             precision    recall  f1-score   support

       I-MF       0.90      0.89      0.89      7170
       I-MM       0.72      0.74      0.73      5529
       I-NE       0.76      0.78      0.77      2290
       I-SE       0.67      0.65      0.66      4080

avg / total       0.78      0.78      0.78     19069

Result for RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',
            max_depth=None, max_features='auto', max_leaf_nodes=None,
            min_impurity_decrease=0.0, min_impurity_split=None,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=1,
            oob_score=False, random_state=1234, verbose=0,
            warm_start=False)
0.788556849427002
[[6420  608   32  110]
 [ 544 4074   62  849]
 [  29   61 1806  394]
 [  97  861  403 2719]]
             precision    recall  f1-score   support

       I-MF       0.91      0.90      0.90      7170
       I-MM       0.73      0.74      0.73      5529
       I-NE       0.78      0.79      0.79      2290
       I-SE       0.67      0.67      0.67      4080

avg / total       0.79      0.79      0.79     19069

Result for AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,
          learning_rate=1.0, n_estimators=50, random_state=None)
0.5811518121506285
[[5647 1394    9  120]
 [1473 3091   95  870]
 [ 218  492  834  746]
 [ 428 1771  423 1458]]
             precision    recall  f1-score   support

       I-MF       0.73      0.79      0.76      7170
       I-MM       0.46      0.56      0.50      5529
       I-NE       0.61      0.36      0.46      2290
       I-SE       0.46      0.36      0.40      4080

avg / total       0.58      0.58      0.57     19069

Result for LinearDiscriminantAnalysis(n_components=None, priors=None, shrinkage=None,
              solver='svd', store_covariance=False, tol=0.0001)
0.5761177547127142
[[5829 1180    2  159]
 [1707 2708   44 1070]
 [ 276  392  679  943]
 [ 494 1550  263 1773]]
             precision    recall  f1-score   support

       I-MF       0.70      0.81      0.75      7170
       I-MM       0.46      0.49      0.48      5529
       I-NE       0.69      0.30      0.41      2290
       I-SE       0.45      0.43      0.44      4080

avg / total       0.58      0.58      0.57     19069

Result for QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
               store_covariance=False, store_covariances=None, tol=0.0001)
0.5824118465629747
[[5839 1132    6  193]
 [1640 2620   49 1220]
 [ 263  351  668 1008]
 [ 518 1380  193 1989]]
             precision    recall  f1-score   support

       I-MF       0.71      0.81      0.76      7170
       I-MM       0.48      0.47      0.48      5529
       I-NE       0.73      0.29      0.42      2290
       I-SE       0.45      0.49      0.47      4080

avg / total       0.59      0.58      0.57     19069

Result for LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,
     intercept_scaling=1, loss='squared_hinge', max_iter=1000,
     multi_class='ovr', penalty='l2', random_state=1234, tol=0.0001,
     verbose=0)
0.5372067673579032
[[6450  562    0  158]
 [2686 1776    0 1067]
 [ 409  270   72 1539]
 [ 943 1194    0 1943]]
             precision    recall  f1-score   support

       I-MF       0.61      0.90      0.73      7170
       I-MM       0.47      0.32      0.38      5529
       I-NE       1.00      0.03      0.06      2290
       I-SE       0.41      0.48      0.44      4080

avg / total       0.58      0.54      0.49     19069

Result for MLPClassifier(activation='relu', alpha=1, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(100,), learning_rate='constant',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       nesterovs_momentum=True, power_t=0.5, random_state=None,
       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,
       verbose=False, warm_start=False)
0.5656306554908161
[[6021 1042    0  107]
 [1947 2691    7  884]
 [ 301  520  329 1140]
 [ 590 1695   43 1752]]
             precision    recall  f1-score   support

       I-MF       0.68      0.84      0.75      7170
       I-MM       0.45      0.49      0.47      5529
       I-NE       0.87      0.14      0.25      2290
       I-SE       0.45      0.43      0.44      4080

avg / total       0.59      0.57      0.54     19069

Result for GradientBoostingClassifier(criterion='friedman_mse', init=None,
              learning_rate=0.1, loss='deviance', max_depth=5,
              max_features=None, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=1, min_samples_split=2,
              min_weight_fraction_leaf=0.0, n_estimators=100,
              presort='auto', random_state=1234, subsample=1.0, verbose=0,
              warm_start=False)
0.6224244251724056
[[5803 1221    6  140]
 [1377 3192   72  888]
 [ 195  402 1025  668]
 [ 433 1538  249 1860]]
             precision    recall  f1-score   support

       I-MF       0.74      0.81      0.77      7170
       I-MM       0.50      0.58      0.54      5529
       I-NE       0.76      0.45      0.56      2290
       I-SE       0.52      0.46      0.49      4080

avg / total       0.63      0.62      0.62     19069
