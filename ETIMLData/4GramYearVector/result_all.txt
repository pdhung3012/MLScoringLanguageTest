Result for GaussianNB(priors=None, var_smoothing=1e-09)
[[2370  440    0    0]
 [ 868  717    0    0]
 [  79 1143  270    0]
 [ 530 1125    0    0]]
              precision    recall  f1-score   support

        I-MF       0.62      0.84      0.71      2810
        I-MM       0.21      0.45      0.29      1585
        I-NE       1.00      0.18      0.31      1492
        I-SE       0.00      0.00      0.00      1655

   micro avg       0.45      0.45      0.45      7542
   macro avg       0.46      0.37      0.33      7542
weighted avg       0.47      0.45      0.39      7542

Result for LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='warn',
          n_jobs=None, penalty='l2', random_state=1234, solver='warn',
          tol=0.0001, verbose=0, warm_start=False)
[[2810    0    0    0]
 [1585    0    0    0]
 [1492    0    0    0]
 [1655    0    0    0]]
              precision    recall  f1-score   support

        I-MF       0.37      1.00      0.54      2810
        I-MM       0.00      0.00      0.00      1585
        I-NE       0.00      0.00      0.00      1492
        I-SE       0.00      0.00      0.00      1655

   micro avg       0.37      0.37      0.37      7542
   macro avg       0.09      0.25      0.14      7542
weighted avg       0.14      0.37      0.20      7542

Result for DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,
            max_features=None, max_leaf_nodes=None,
            min_impurity_decrease=0.0, min_impurity_split=None,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, presort=False, random_state=None,
            splitter='best')
[[2175  402  104  129]
 [ 304  916  100  265]
 [  35  109 1157  191]
 [ 178  310  260  907]]
              precision    recall  f1-score   support

        I-MF       0.81      0.77      0.79      2810
        I-MM       0.53      0.58      0.55      1585
        I-NE       0.71      0.78      0.74      1492
        I-SE       0.61      0.55      0.58      1655

   micro avg       0.68      0.68      0.68      7542
   macro avg       0.66      0.67      0.67      7542
weighted avg       0.69      0.68      0.68      7542

Result for RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',
            max_depth=None, max_features='auto', max_leaf_nodes=None,
            min_impurity_decrease=0.0, min_impurity_split=None,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=None,
            oob_score=False, random_state=1234, verbose=0,
            warm_start=False)
[[2526  223   25   36]
 [ 203 1180   75  127]
 [  20   52 1301  119]
 [ 120  270  214 1051]]
              precision    recall  f1-score   support

        I-MF       0.88      0.90      0.89      2810
        I-MM       0.68      0.74      0.71      1585
        I-NE       0.81      0.87      0.84      1492
        I-SE       0.79      0.64      0.70      1655

   micro avg       0.80      0.80      0.80      7542
   macro avg       0.79      0.79      0.79      7542
weighted avg       0.80      0.80      0.80      7542

Result for AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,
          learning_rate=1.0, n_estimators=50, random_state=None)
[[2357  371   78    4]
 [ 325  650  417  193]
 [  26   15 1396   55]
 [ 101  341  664  549]]
              precision    recall  f1-score   support

        I-MF       0.84      0.84      0.84      2810
        I-MM       0.47      0.41      0.44      1585
        I-NE       0.55      0.94      0.69      1492
        I-SE       0.69      0.33      0.45      1655

   micro avg       0.66      0.66      0.66      7542
   macro avg       0.64      0.63      0.60      7542
weighted avg       0.67      0.66      0.64      7542

Result for LinearDiscriminantAnalysis(n_components=None, priors=None, shrinkage=None,
              solver='svd', store_covariance=False, tol=0.0001)
[[2534  247    0   29]
 [ 124 1356    2  103]
 [  29  250  907  306]
 [ 123  244   18 1270]]
              precision    recall  f1-score   support

        I-MF       0.90      0.90      0.90      2810
        I-MM       0.65      0.86      0.74      1585
        I-NE       0.98      0.61      0.75      1492
        I-SE       0.74      0.77      0.76      1655

   micro avg       0.80      0.80      0.80      7542
   macro avg       0.82      0.78      0.79      7542
weighted avg       0.83      0.80      0.80      7542

Result for QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
               store_covariance=False, store_covariances=None, tol=0.0001)
[[2171  108  152  379]
 [ 103  711   35  736]
 [   3    8 1322  159]
 [ 132   93  184 1246]]
              precision    recall  f1-score   support

        I-MF       0.90      0.77      0.83      2810
        I-MM       0.77      0.45      0.57      1585
        I-NE       0.78      0.89      0.83      1492
        I-SE       0.49      0.75      0.60      1655

   micro avg       0.72      0.72      0.72      7542
   macro avg       0.74      0.72      0.71      7542
weighted avg       0.76      0.72      0.72      7542

Result for LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,
     intercept_scaling=1, loss='squared_hinge', max_iter=1000,
     multi_class='ovr', penalty='l2', random_state=1234, tol=0.0001,
     verbose=0)
[[   0 2810    0    0]
 [   0 1585    0    0]
 [   0 1492    0    0]
 [   0 1655    0    0]]
              precision    recall  f1-score   support

        I-MF       0.00      0.00      0.00      2810
        I-MM       0.21      1.00      0.35      1585
        I-NE       0.00      0.00      0.00      1492
        I-SE       0.00      0.00      0.00      1655

   micro avg       0.21      0.21      0.21      7542
   macro avg       0.05      0.25      0.09      7542
weighted avg       0.04      0.21      0.07      7542

Result for MLPClassifier(activation='relu', alpha=1, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(100,), learning_rate='constant',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,
       random_state=None, shuffle=True, solver='adam', tol=0.0001,
       validation_fraction=0.1, verbose=False, warm_start=False)
[[2810    0    0    0]
 [1585    0    0    0]
 [1492    0    0    0]
 [1655    0    0    0]]
              precision    recall  f1-score   support

        I-MF       0.37      1.00      0.54      2810
        I-MM       0.00      0.00      0.00      1585
        I-NE       0.00      0.00      0.00      1492
        I-SE       0.00      0.00      0.00      1655

   micro avg       0.37      0.37      0.37      7542
   macro avg       0.09      0.25      0.14      7542
weighted avg       0.14      0.37      0.20      7542

Result for GradientBoostingClassifier(criterion='friedman_mse', init=None,
              learning_rate=0.1, loss='deviance', max_depth=5,
              max_features=None, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=1, min_samples_split=2,
              min_weight_fraction_leaf=0.0, n_estimators=100,
              n_iter_no_change=None, presort='auto', random_state=1234,
              subsample=1.0, tol=0.0001, validation_fraction=0.1,
              verbose=0, warm_start=False)
[[2521  220   47   22]
 [ 152 1274   83   76]
 [  16   26 1344  106]
 [ 123  259  198 1075]]
              precision    recall  f1-score   support

        I-MF       0.90      0.90      0.90      2810
        I-MM       0.72      0.80      0.76      1585
        I-NE       0.80      0.90      0.85      1492
        I-SE       0.84      0.65      0.73      1655

   micro avg       0.82      0.82      0.82      7542
   macro avg       0.81      0.81      0.81      7542
weighted avg       0.83      0.82      0.82      7542

