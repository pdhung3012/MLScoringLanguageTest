Result for GaussianNB(priors=None, var_smoothing=1e-09)
0.5185192671237445
[[1641  573   27  289]
 [ 760  672  133  636]
 [  47  106  982  277]
 [ 280  329  241  696]]
              precision    recall  f1-score   support

        I-MF       0.60      0.65      0.62      2530
        I-MM       0.40      0.31      0.35      2201
        I-NE       0.71      0.70      0.70      1412
        I-SE       0.37      0.45      0.40      1546

   micro avg       0.52      0.52      0.52      7689
   macro avg       0.52      0.52      0.52      7689
weighted avg       0.52      0.52      0.51      7689

Result for LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='warn',
          n_jobs=None, penalty='l2', random_state=1234, solver='warn',
          tol=0.0001, verbose=0, warm_start=False)
0.5566439086810886
[[2219  276   35    0]
 [1137  917  147    0]
 [  83  218 1111    0]
 [ 433  762  314   37]]
              precision    recall  f1-score   support

        I-MF       0.57      0.88      0.69      2530
        I-MM       0.42      0.42      0.42      2201
        I-NE       0.69      0.79      0.74      1412
        I-SE       1.00      0.02      0.05      1546

   micro avg       0.56      0.56      0.56      7689
   macro avg       0.67      0.53      0.47      7689
weighted avg       0.64      0.56      0.49      7689

Result for DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,
            max_features=None, max_leaf_nodes=None,
            min_impurity_decrease=0.0, min_impurity_split=None,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, presort=False, random_state=None,
            splitter='best')
0.7315667756154368
[[1859  492   31  148]
 [ 498 1398   99  206]
 [  41  102 1179   90]
 [ 148  174  102 1122]]
              precision    recall  f1-score   support

        I-MF       0.73      0.73      0.73      2530
        I-MM       0.65      0.64      0.64      2201
        I-NE       0.84      0.83      0.84      1412
        I-SE       0.72      0.73      0.72      1546

   micro avg       0.72      0.72      0.72      7689
   macro avg       0.73      0.73      0.73      7689
weighted avg       0.72      0.72      0.72      7689

Result for RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',
            max_depth=None, max_features='auto', max_leaf_nodes=None,
            min_impurity_decrease=0.0, min_impurity_split=None,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=None,
            oob_score=False, random_state=1234, verbose=0,
            warm_start=False)
0.7991954458933409
[[2037  411   14   68]
 [ 368 1658   63  112]
 [  30   90 1248   44]
 [ 116  144   85 1201]]
              precision    recall  f1-score   support

        I-MF       0.80      0.81      0.80      2530
        I-MM       0.72      0.75      0.74      2201
        I-NE       0.89      0.88      0.88      1412
        I-SE       0.84      0.78      0.81      1546

   micro avg       0.80      0.80      0.80      7689
   macro avg       0.81      0.80      0.81      7689
weighted avg       0.80      0.80      0.80      7689

Result for AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,
          learning_rate=1.0, n_estimators=50, random_state=None)
0.6485858653379604
[[1955  538   11   26]
 [ 708 1227   78  188]
 [   8  141 1100  163]
 [ 209  537  142  658]]
              precision    recall  f1-score   support

        I-MF       0.68      0.77      0.72      2530
        I-MM       0.50      0.56      0.53      2201
        I-NE       0.83      0.78      0.80      1412
        I-SE       0.64      0.43      0.51      1546

   micro avg       0.64      0.64      0.64      7689
   macro avg       0.66      0.63      0.64      7689
weighted avg       0.65      0.64      0.64      7689

Result for LinearDiscriminantAnalysis(n_components=None, priors=None, shrinkage=None,
              solver='svd', store_covariance=False, tol=0.0001)
0.7677193712057993
[[1932  463    1  134]
 [ 294 1736   12  159]
 [  47  164  934  267]
 [  97  136   20 1293]]
              precision    recall  f1-score   support

        I-MF       0.82      0.76      0.79      2530
        I-MM       0.69      0.79      0.74      2201
        I-NE       0.97      0.66      0.79      1412
        I-SE       0.70      0.84      0.76      1546

   micro avg       0.77      0.77      0.77      7689
   macro avg       0.79      0.76      0.77      7689
weighted avg       0.78      0.77      0.77      7689

Result for QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
               store_covariance=False, store_covariances=None, tol=0.0001)
0.7922937344030043
[[1960  464   12   94]
 [ 292 1773   33  103]
 [   8  145 1077  182]
 [  65  149   45 1287]]
              precision    recall  f1-score   support

        I-MF       0.84      0.77      0.81      2530
        I-MM       0.70      0.81      0.75      2201
        I-NE       0.92      0.76      0.84      1412
        I-SE       0.77      0.83      0.80      1546

   micro avg       0.79      0.79      0.79      7689
   macro avg       0.81      0.79      0.80      7689
weighted avg       0.80      0.79      0.79      7689

Result for LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,
     intercept_scaling=1, loss='squared_hinge', max_iter=1000,
     multi_class='ovr', penalty='l2', random_state=1234, tol=0.0001,
     verbose=0)
0.7447005618533357
[[2266  192   30   42]
 [ 742 1285  103   71]
 [  58   88 1205   61]
 [ 237  157  178  974]]
              precision    recall  f1-score   support

        I-MF       0.69      0.90      0.78      2530
        I-MM       0.75      0.58      0.66      2201
        I-NE       0.79      0.85      0.82      1412
        I-SE       0.85      0.63      0.72      1546

   micro avg       0.75      0.75      0.75      7689
   macro avg       0.77      0.74      0.74      7689
weighted avg       0.76      0.75      0.74      7689

Result for MLPClassifier(activation='relu', alpha=1, batch_size='auto', beta_1=0.9,
       beta_2=0.999, early_stopping=False, epsilon=1e-08,
       hidden_layer_sizes=(100,), learning_rate='constant',
       learning_rate_init=0.001, max_iter=200, momentum=0.9,
       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,
       random_state=None, shuffle=True, solver='adam', tol=0.0001,
       validation_fraction=0.1, verbose=False, warm_start=False)
0.5308931040637453
[[2048  450   32    0]
 [1092  951  158    0]
 [  48  274 1090    0]
 [ 391  817  338    0]]
              precision    recall  f1-score   support

        I-MF       0.57      0.81      0.67      2530
        I-MM       0.38      0.43      0.41      2201
        I-NE       0.67      0.77      0.72      1412
        I-SE       0.00      0.00      0.00      1546

   micro avg       0.53      0.53      0.53      7689
   macro avg       0.41      0.50      0.45      7689
weighted avg       0.42      0.53      0.47      7689

Result for GradientBoostingClassifier(criterion='friedman_mse', init=None,
              learning_rate=0.1, loss='deviance', max_depth=5,
              max_features=None, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=1, min_samples_split=2,
              min_weight_fraction_leaf=0.0, n_estimators=100,
              n_iter_no_change=None, presort='auto', random_state=1234,
              subsample=1.0, tol=0.0001, validation_fraction=0.1,
              verbose=0, warm_start=False)
0.8023157053206571
[[2064  389   15   62]
 [ 365 1653   67  116]
 [  16   82 1262   52]
 [ 102  144   77 1223]]
              precision    recall  f1-score   support

        I-MF       0.81      0.82      0.81      2530
        I-MM       0.73      0.75      0.74      2201
        I-NE       0.89      0.89      0.89      1412
        I-SE       0.84      0.79      0.82      1546

   micro avg       0.81      0.81      0.81      7689
   macro avg       0.82      0.81      0.81      7689
weighted avg       0.81      0.81      0.81      7689

